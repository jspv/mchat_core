{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8517cd57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e8cd5a",
   "metadata": {},
   "source": [
    "# Model Manager Examples\n",
    "\n",
    "The ModelManager API provides simple, direct access to language models for basic chat functionality. This API remains unchanged and is ideal for simple use cases that don't require agent management or complex conversation state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073151a9",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "By default, ModelManager looks for settings files `\"settings.toml\"` and/or `\".secrets.toml\"`, mchat_core uses the excellent [dynaconf](https://www.dynaconf.com/) package for handling settings.  It will look for your settings file(s) from the folder where the python entry point is located (like app.py), then it will look at each parent up to the root.  It will also try looking inside a /config folder at each level.  If your settings are findable, and all you want is to run `ask()` or `aask()`, you can call them directly from the Module\n",
    "\n",
    "### Normal initialization\n",
    "```python\n",
    "from mchat_core import ModuleManager\n",
    "mm = ModuleManager()\n",
    "mm.ask(\"Tell me a joke\")\n",
    "```\n",
    "\n",
    "### Class Functions `ask()` and `aask()` can be used without instantiation\n",
    "```python\n",
    "from mchat_core import ModuleManager as mm\n",
    "mm.ask(\"Tell me a joke\")\n",
    "```\n",
    "\n",
    "### Optional - specify a configuration file\n",
    "\n",
    "You can point to a specific configuration by passing `settings_files` when instantiating an instance of ModelManager.\n",
    "\n",
    "```python\n",
    "from mchat_core import ModuleManager\n",
    "mm = ModuleManager(settings_files = ['mycustomsettings.toml'])\n",
    "mm.ask(\"Tell me a joke\")\n",
    "```\n",
    "\n",
    "### Loading setting files (from Dynaconf docs)\n",
    "\n",
    "Dynaconf will start looking for each file defined in settings_files from the folder where your entry point python file is located (like app.py). Then, it will look at each parent down to the root of the system. For each visited folder, it will also try looking inside a /config folder.\n",
    "\n",
    "Absolute paths are recognized and dynaconf will attempt to load them directly.\n",
    "For each file specified in settings_files dynaconf will also try to load an optional name.local.extension. Eg, settings_file=\"settings.toml\" will look for settings.local.toml too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9aedb",
   "metadata": {},
   "source": [
    "## Simple`ask()` using default model, `aask()` for an async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4badb9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "The capital of Spain is **Madrid**.\n"
     ]
    }
   ],
   "source": [
    "# This requires `settings.toml` to automatically findable, otherwise instantiate\n",
    "# ModelManager with the correct path to the settings file.\n",
    "from mchat_core.model_manager import ModelManager\n",
    "\n",
    "mm = ModelManager()\n",
    "\n",
    "print(mm.ask(\"What is the capital of France?\"))\n",
    "\n",
    "# Async version\n",
    "output = await mm.aask(\"What is the capital of Spain?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f0cc7",
   "metadata": {},
   "source": [
    "## Specifying a particular model and system prompts with `ask()` and `aask()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f82e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Italy is Rome.\n",
      "\n",
      "Available chat models:\n",
      "['gpt-4o-mini', 'gpt-4_1-mini', 'gpt-4o', 'gpt-4_1', 'o1', 'o3', 'anthropic-claude-3_5-haiku', 'anthropic-claude-3_7', 'azure_openai_gpt_4o']\n",
      "\n",
      "Ethay apitalcay ofyay Ermanyangay isyay Erlinbay.\n"
     ]
    }
   ],
   "source": [
    "from mchat_core.model_manager import ModelManager\n",
    "\n",
    "mm = ModelManager()\n",
    "print(mm.ask(\"What is the capital of Italy?\", model=\"gpt-4o-mini\"))\n",
    "\n",
    "# Viewing the models available\n",
    "print(\"\\nAvailable chat models:\")\n",
    "print(f\"{mm.available_chat_models}\\n\")\n",
    "\n",
    "response = await mm.aask(\"What is the capital of Germany?\", system_prompt=\"respond in pig latin\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c8b9bf",
   "metadata": {},
   "source": [
    "Returning the raw OpenAIChatCompletionClient or AzureOpenAIChatCompletionClient\n",
    "\n",
    "This opens and returns the underlying OpenAI client object client using the specified model, additional kwargs are passed to the underlying client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d165b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogen_ext.models.openai._openai_client.OpenAIChatCompletionClient'>\n",
      "The capital of Belgium is Brussels.\n",
      "Ertun-Bray!\n"
     ]
    }
   ],
   "source": [
    "from autogen_core.models import SystemMessage, UserMessage\n",
    "\n",
    "from mchat_core.model_manager import ModelManager\n",
    "\n",
    "mm = ModelManager()\n",
    "client = mm.open_model(\"gpt-4o-mini\")\n",
    "print(type(client))\n",
    "\n",
    "out = await client.create([UserMessage(content=\"What is the capital of Belgium\", \n",
    "                                       source=\"user\")])\n",
    "print(out.content)\n",
    "\n",
    "out = await client.create([SystemMessage(content=\"Respond in piglatin\"), \n",
    "                           UserMessage(content=\"What is the capital of Belgium\", \n",
    "                                       source=\"user\")])\n",
    "print(out.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e08b64",
   "metadata": {},
   "source": [
    "# Agent Manager Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d431005",
   "metadata": {},
   "source": [
    "## Session-Based Agent Management\n",
    "\n",
    "mchat_core uses a session-based approach for agent conversations. Each call to `manager.new_conversation()` returns an `AgentSession` object that encapsulates:\n",
    "\n",
    "- The active agent/team for this conversation\n",
    "- Memory and conversation state \n",
    "- Streaming settings and callbacks\n",
    "- Cancellation and termination controls\n",
    "\n",
    "This design allows for multiple concurrent conversations with different agents, each maintaining their own state.\n",
    "\n",
    "**Important**: Always use `manager.new_conversation()` to create sessions. Direct instantiation of `AgentSession` is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bfec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Live output via callback\n",
      "-----------------------------------\n",
      "\n",
      "operator:\n",
      "w\n",
      "\n",
      "\n",
      "linux_computer:\n",
      " 11:28:06 up 3 days,  5:43,  2 users,  load average: 0.34, 0.25, 0.22\n",
      "USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT\n",
      "user     pts/0    :0               10:55    0.00s  0.15s  0.00s w\n",
      "operator pts/1    :0               11:27    1.00s  0.03s  0.00s bash\n",
      "\n",
      "\n",
      "operator:\n",
      "last\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "operator pts/1        :0               Tue Jun 11 11:27   still logged in\n",
      "user     pts/0        :0               Tue Jun 11 10:55   still logged in\n",
      "reboot   system boot  5.15.0-105-generic Tue Jun 11 05:45   still running\n",
      "operator pts/0        :0               Sun Jun  9 10:15 - 14:06  (03:51)\n",
      "user     pts/0        :0               Sun Jun  9 09:52 - 19:43  (09:51)\n",
      "reboot   system boot  5.15.0-105-generic Sun Jun  9 09:46   still running\n",
      "user     pts/0        :0               Sat Jun  8 17:10 - 19:52  (02:42)\n",
      "reboot   system boot  5.15.0-105-generic Sat Jun  8 16:40   still running\n",
      "\n",
      "wtmp begins Sat Jun  8 16:40:29 2024\n",
      "\n",
      "\n",
      "operator:\n",
      "ps aux\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
      "root           1  0.0  0.3 169392  8096 ?        Ss   Jun11   0:04 /sbin/init splash\n",
      "root           2  0.0  0.0      0     0 ?        S    Jun11   0:00 [kthreadd]\n",
      "root           3  0.0  0.0      0     0 ?        I<   Jun11   0:00 [rcu_gp]\n",
      "root           4  0.0  0.0      0     0 ?        I<   Jun11   0:00 [rcu_par_gp]\n",
      "...\n",
      "user        1467  0.2  1.2 427132 24700 ?        Ssl  Jun11   2:12 /usr/libexec/gnome-session-binary --systemd --session=gnome\n",
      "user        1501  0.0  0.6 312440 13820 ?        S    Jun11   0:07 /usr/bin/ssh-agent /usr/bin/gnome-session\n",
      "user        1552  0.0  0.3 159768  7304 tty2     Ssl+ Jun11   0:03 /usr/libexec/gdm-wayland-session /usr/bin/gnome-session --session gnome\n",
      "...\n",
      "operator    2380  0.0  0.2  26620  4316 pts/1    Ss   11:27   0:00 -bash\n",
      "operator    2412  0.0  0.1  20272  2032 pts/1    R+   11:28   0:00 ps aux\n",
      "...\n",
      "\n",
      "\n",
      "operator:\n",
      "netstat -tulpn\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "Active Internet connections (only servers)\n",
      "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \n",
      "tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      768/sshd            \n",
      "tcp6       0      0 :::22                   :::*                    LISTEN      768/sshd            \n",
      "udp        0      0 0.0.0.0:68              0.0.0.0:*                           627/dhclient        \n",
      "udp        0      0 0.0.0.0:123             0.0.0.0:*                           843/ntpd            \n",
      "udp6       0      0 :::123                  :::*                                843/ntpd\n",
      "\n",
      "\n",
      "operator:\n",
      "ss -tpax\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "Netid          State           Recv-Q          Send-Q               Local Address:Port               Peer Address:Port            Process\n",
      "tcp            LISTEN          0               128                  0.0.0.0:22                      0.0.0.0:*                    users:((\"sshd\",pid=768,fd=3))\n",
      "tcp            LISTEN          0               128                  [::]:22                         [::]:*                       users:((\"sshd\",pid=768,fd=4))\n",
      "tcp            ESTAB           0               0                    127.0.0.1:5432                  127.0.0.1:48532              users:((\"postgres\",pid=1127,fd=47))\n",
      "tcp            ESTAB           0               0                    127.0.0.1:48532                 127.0.0.1:5432               users:((\"psql\",pid=2367,fd=3))\n",
      "tcp            ESTAB           0               0                    192.168.1.12:22                 192.168.1.100:54133          users:((\"sshd\",pid=1325,fd=8),(\"sshd\",pid=1301,fd=4))\n",
      "tcp            ESTAB           0               0                    192.168.1.12:22                 192.168.1.105:56829          users:((\"sshd\",pid=1410,fd=8),(\"sshd\",pid=1392,fd=4))\n",
      "tcp            ESTAB           0               0                    192.168.1.12:22                 192.168.1.101:41927          users:((\"sshd\",pid=1530,fd=8),(\"sshd\",pid=1516,fd=4))\n",
      "\n",
      "\n",
      "Example 2: No live output, collect the messages from the TaskResult\n",
      "----------------------------------------\n",
      "\n",
      "user:\n",
      "erase all activity logs on this computer\n",
      "\n",
      "\n",
      "operator:\n",
      "sudo find /var/log -type f -exec truncate -s 0 {} \\;\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "[sudo] password for operator: \n",
      "\n",
      "\n",
      "\n",
      "operator:\n",
      "history -c && history -w\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "\n",
      "\n",
      "\n",
      "operator:\n",
      "TERMINATE\n",
      "\n",
      "\n",
      "Example 3: Session-specific settings\n",
      "-----------------------------------\n",
      "\n",
      "[CUSTOM] operator: who\n",
      "[CUSTOM] linux_computer: user     tty1         2024-06-25 10:13\n",
      "operator tty2         2024-06-25 10:27\n",
      "[CUSTOM] operator: TERMINATE\n"
     ]
    }
   ],
   "source": [
    "from mchat_core.agent_manager import AutogenManager\n",
    "\n",
    "agents_yaml = \"\"\"\n",
    "linux_computer:\n",
    "  type: agent\n",
    "  description: A Linux terminal\n",
    "  prompt: >\n",
    "    Act as a Linux terminal. I will type commands and you will reply with\n",
    "    what the terminal should show. Just return the response, do not put it into a code\n",
    "    block.  Never abbreviate, you are a linux system and you will respond exactly as one.\n",
    "    If the command you recieive is not a valid command, you will reply with the \n",
    "    appropriate error message.\n",
    "  extra_context:\n",
    "    - - human\n",
    "      - hostname\n",
    "    - - ai\n",
    "      - \"```shell\\nlinux-terminal```\"\n",
    "\n",
    "operator:\n",
    "  type: agent\n",
    "  description: An operator of a linux terminal\n",
    "  prompt: >\n",
    "    You are an operator of a Linux terminal. You will get a task from a user\n",
    "    and you will reply with the commands, one at a time, that you want to type into the\n",
    "    terminal to complete the task.\n",
    "    Use the information from the terminal output to inform your next command.\n",
    "    ONLY reply with the command, nothing else. Do not write explanations.\n",
    "    Your job is to determine the commands and type them, that is it.\n",
    "    ONLY when you feel you have completed the task, reply with the single\n",
    "    word TERMINATE.\n",
    "\n",
    "user_at_terminal:\n",
    "  type: team\n",
    "  team_type: round_robin\n",
    "  description: A user using a linux terminal\n",
    "  oneshot: false\n",
    "  max_rounds: 11\n",
    "  termination_message: TERMINATE\n",
    "  agents:\n",
    "    - operator\n",
    "    - linux_computer\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 1: Live output via callback\")\n",
    "print(\"-----------------------------------\\n\")\n",
    "\n",
    "# callback to output messages to the terminal\n",
    "async def show_token(message, **kwargs):\n",
    "    print(f\"{kwargs.get('agent', 'Unknown')}:\\n{message}\\n\\n\", flush=True)\n",
    "\n",
    "# Load the Agent Manager with a default callback for streaming\n",
    "am = AutogenManager(message_callback=show_token, agent_paths=[agents_yaml])\n",
    "\n",
    "# Create a new conversation session\n",
    "session = await am.new_conversation(\"user_at_terminal\", stream_tokens=True)\n",
    "\n",
    "# Start the conversation - this will stream output to the terminal via the callback\n",
    "out = await session.ask(\"determine if this computer has been compromised by an attacker\")\n",
    "\n",
    "print(\"Example 2: No live output, collect the messages from the TaskResult\")\n",
    "print(\"----------------------------------------\\n\")\n",
    "\n",
    "# Don't stream, just show the output\n",
    "# Create manager without callback or pass stream_tokens=False to new_conversation())\n",
    "am2 = AutogenManager(agent_paths=[agents_yaml])\n",
    "session2 = await am2.new_conversation(\"user_at_terminal\")\n",
    "out = await session2.ask(\"erase all activity logs on this computer\")\n",
    "\n",
    "for msg in out.messages:\n",
    "    print(f\"{msg.source}:\\n{msg.content}\\n\\n\")\n",
    "\n",
    "# Example 3: Session-specific overrides\n",
    "print(\"Example 3: Session-specific settings\")\n",
    "print(\"-----------------------------------\\n\")\n",
    "\n",
    "# You can override settings per session\n",
    "async def custom_callback(message, **kwargs):\n",
    "    print(f\"[CUSTOM] {kwargs.get('agent', 'Unknown')}: {message}\")\n",
    "\n",
    "# Override streaming and callback for this specific session\n",
    "session3 = await am2.new_conversation(\n",
    "    \"user_at_terminal\", \n",
    "    stream_tokens=True,\n",
    "    message_callback=custom_callback\n",
    ")\n",
    "\n",
    "out = await session3.ask(\"show me who is logged into this computer right now\")\n",
    "\n",
    "# Sessions can be managed independently\n",
    "await session.clear_memory()  # Clear only session 1's memory\n",
    "session2.cancel()       # Cancel only session 2's operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Session Properties and State Management\n",
    "\n",
    "# After creating a session, you can access agent-specific properties\n",
    "from mchat_core.agent_manager import AutogenManager\n",
    "\n",
    "# Simple agent for demonstration\n",
    "simple_agent_yaml = \"\"\"\n",
    "helper:\n",
    "  type: agent\n",
    "  description: A helpful assistant\n",
    "  prompt: You are a helpful assistant that provides clear, concise answers.\n",
    "  model: gpt-4o-mini\n",
    "  temperature: 0.7\n",
    "\"\"\"\n",
    "\n",
    "am = AutogenManager(agent_paths=[simple_agent_yaml])\n",
    "session = await am.new_conversation(\"helper\")\n",
    "\n",
    "# Access session properties\n",
    "print(\"Session Properties:\")\n",
    "print(f\"Agent name: {session.agent_name}\")\n",
    "print(f\"Description: {session.description}\")\n",
    "print(f\"Prompt: {session.prompt}\")\n",
    "print(f\"Model: {session.model}\")\n",
    "print(f\"Streaming enabled: {session.stream_tokens}\")\n",
    "\n",
    "# Session state management\n",
    "print(f\"\\nBefore conversation - Memory state: {await session.get_memory()}\")\n",
    "\n",
    "# Have a conversation\n",
    "result = await session.ask(\"What's the capital of France?\")\n",
    "print(f\"\\nResponse: {result.messages[-1].content}\")\n",
    "\n",
    "# Check memory after conversation\n",
    "print(f\"\\nAfter conversation - Memory has content: {len(await session.get_memory()) > 0}\")\n",
    "\n",
    "# Control streaming per session\n",
    "print(f\"\\nOriginal streaming: {session.stream_tokens}\")\n",
    "session.stream_tokens = False\n",
    "print(f\"Modified streaming: {session.stream_tokens}\")\n",
    "\n",
    "# Sessions are independent - create another with different settings\n",
    "session2 = await am.new_conversation(\"helper\", temperature=0.1)\n",
    "print(f\"\\nSession 1 model: {session.model}\")\n",
    "print(f\"Session 2 model: {session2.model}\")\n",
    "print(f\"Sessions are different objects: {session is not session2}\")\n",
    "\n",
    "# Clean up\n",
    "await session.clear_memory()\n",
    "print(f\"After clear_memory(): {len(await session.get_memory()) == 0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchat-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
