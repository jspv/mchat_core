{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8517cd57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e8cd5a",
   "metadata": {},
   "source": [
    "# Model Manager Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073151a9",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "By default, ModelManager looks for settings files `\"settings.toml\"` and/or `\".secrets.toml\"`, mchat_core uses the excellent [dynaconf](https://www.dynaconf.com/) package for handling settings.  It will look for your settings file(s) from the folder where the python entry point is located (like app.py), then it will look at each parent up to the root.  It will also try looking inside a /config folder at each level.  If your settings are findable, and all you want is to run `ask()` or `aask()`, you can call them directly from the Module\n",
    "\n",
    "### Normal initialization\n",
    "```python\n",
    "from mchat_core import ModuleManager\n",
    "mm = ModuleManager()\n",
    "mm.ask(\"Tell me a joke\")\n",
    "```\n",
    "\n",
    "### Class Functions `ask()` and `aask()` can be used without instantiation\n",
    "```python\n",
    "from mchat_core import ModuleManager as mm\n",
    "mm.ask(\"Tell me a joike\")\n",
    "```\n",
    "\n",
    "### Optional - specify a configuration file\n",
    "\n",
    "You can point to a specific configuration by passing `settings_files` when instantiating an instance of ModelManager. *Note*: if you want to use a custom configuration, you will need to call `ask()` and `aask()` from your instance of ModuleManager and not directly \n",
    "\n",
    "```python\n",
    "from mchat_core import ModuleManager\n",
    "mm = ModuleManager(settings_files = ['mycustomsettings.toml'])\n",
    "mm.ask(\"Tell me a joke\")\n",
    "```\n",
    "\n",
    "### Loading setting files (from Dynaconf docs)\n",
    "\n",
    "Dynaconf will start looking for each file defined in settings_files from the folder where your entry point python file is located (like app.py). Then, it will look at each parent down to the root of the system. For each visited folder, it will also try looking inside a /config folder.\n",
    "\n",
    "Absolute paths are recognized and dynaconf will attempt to load them directly.\n",
    "For each file specified in settings_files dynaconf will also try to load an optional name.local.extension. Eg, settings_file=\"settings.toml\" will look for settings.local.toml too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9aedb",
   "metadata": {},
   "source": [
    "## Simple`ask()` using default model, `aask()` for an async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4badb9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**.\n",
      "The capital of Spain is **Madrid**.\n"
     ]
    }
   ],
   "source": [
    "# This requires `settings.toml` to automatically findable, otherwise instantiate\n",
    "# ModelManager with the correct path to the settings file.\n",
    "from mchat_core.model_manager import ModelManager\n",
    "\n",
    "mm = ModelManager()\n",
    "\n",
    "print(mm.ask(\"What is the capital of France?\"))\n",
    "\n",
    "# Async version\n",
    "output = await mm.aask(\"What is the capital of Spain?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f0cc7",
   "metadata": {},
   "source": [
    "## Specifying a particular model and system prompts with `ask()` and `aask()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f82e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Italy is Rome.\n",
      "\n",
      "Available chat models:\n",
      "['gpt-4o-mini', 'gpt-4_1-mini', 'gpt-4o', 'gpt-4_1', 'o1', 'o3', 'anthropic-claude-3_5-haiku', 'anthropic-claude-3_7', 'azure_openai_gpt_4o']\n",
      "\n",
      "Ethay apitalcay ofay ermanyGay isay erlinBay.\n"
     ]
    }
   ],
   "source": [
    "from mchat_core.model_manager import ModelManager\n",
    "\n",
    "mm = ModelManager()\n",
    "print(mm.ask(\"What is the capital of Italy?\", model=\"gpt-4o-mini\"))\n",
    "\n",
    "# Viewing the models available\n",
    "print(\"\\nAvailable chat models:\")\n",
    "print(f\"{mm.available_chat_models}\\n\")\n",
    "\n",
    "response = await mm.aask(\"What is the capital of Germany?\", system_prompt=\"respond in pig latin\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c8b9bf",
   "metadata": {},
   "source": [
    "## Fully opening a specific model client (returns OpenAIChatCompletionClient or AzureOpenAIChatCompletionClient)\n",
    "\n",
    "This opens and returns the autogen client using the specified model, additional kwargs are passed to the underlying client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d165b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogen_ext.models.openai._openai_client.OpenAIChatCompletionClient'>\n",
      "The capital of Belgium is Brussels.\n",
      "Ethay apitalcay ofway ElgiumBay isway RusselsBay.\n"
     ]
    }
   ],
   "source": [
    "from autogen_core.models import SystemMessage, UserMessage\n",
    "from mchat_core.model_manager import ModelManager\n",
    "\n",
    "mm = ModelManager()\n",
    "client = mm.open_model(\"gpt-4o-mini\")\n",
    "print(type(client))\n",
    "\n",
    "out = await client.create([UserMessage(content=\"What is the capital of Belgium\", \n",
    "                                       source=\"user\")])\n",
    "print(out.content)\n",
    "\n",
    "out = await client.create([SystemMessage(content=\"Respond in piglatin\"), \n",
    "                           UserMessage(content=\"What is the capital of Belgium\", \n",
    "                                       source=\"user\")])\n",
    "print(out.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e08b64",
   "metadata": {},
   "source": [
    "# Agent Manager Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d431005",
   "metadata": {},
   "source": [
    "## Basic Round Robin with two Agents\n",
    "\n",
    "This example is a `team' of two agents.  One agent is simulating a linux terminal and the second agent is simulating the user of that terminal trying to solve a task.  The flow alternates between the two in the order specifified in the 'team' definition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7bfec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Live output via callback\n",
      "-----------------------------------\n",
      "\n",
      "operator:\n",
      "lastlog | grep -v \"Never logged in\"\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "Username         Port     From             Latest\n",
      "root             pts/0    192.168.1.20     Wed Jun 12 10:15:33 +0000 2024\n",
      "user             pts/1    10.0.2.15        Tue Jun 11 08:22:05 +0000 2024\n",
      "\n",
      "\n",
      "operator:\n",
      "w\n",
      "\n",
      "\n",
      "linux_computer:\n",
      " 10:36:50 up  2:55,  2 users,  load average: 0.03, 0.04, 0.01\n",
      "USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT\n",
      "root     pts/0    192.168.1.20     10:15    0.00s  0.20s  0.02s w\n",
      "user     pts/1    10.0.2.15        08:22    1:30m  0.01s  0.01s -bash\n",
      "\n",
      "\n",
      "operator:\n",
      "whoami\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "operator\n",
      "\n",
      "\n",
      "operator:\n",
      "ps aux --sort=-%cpu | head -n 15\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
      "root        1123  2.3  0.8 168400  7424 pts/0    Ss   10:15   0:01 /usr/bin/python3 /usr/bin/somecpuintensiveprocess\n",
      "root        1022  1.1  0.5 105600  4888 pts/0    Ss   10:16   0:00 /usr/bin/python3 /usr/bin/anotherprocess\n",
      "operator    1528  0.7  0.1  10092   980 pts/2    Ss   10:35   0:00 bash\n",
      "root        998   0.3  0.7 100500  6876 tty1     Ss+  07:46   0:01 /sbin/getty -8 38400 tty1\n",
      "operator    1602  0.2  0.1  10088   952 pts/2    S+   10:36   0:00 ps aux --sort=-%cpu\n",
      "root        1     0.0  0.1  11160  1020 ?        Ss   07:45   0:01 /sbin/init\n",
      "root        2     0.0  0.0      0     0 ?        S    07:45   0:00 [kthreadd]\n",
      "root        3     0.0  0.0      0     0 ?        I<   07:45   0:00 [rcu_gp]\n",
      "root        4     0.0  0.0      0     0 ?        I<   07:45   0:00 [rcu_par_gp]\n",
      "root        6     0.0  0.0      0     0 ?        I<   07:45   0:00 [kworker/0:0H-events_highpri]\n",
      "root        8     0.0  0.0      0     0 ?        I<   07:45   0:00 [mm_percpu_wq]\n",
      "root        9     0.0  0.0      0     0 ?        S    07:45   0:00 [rcu_tasks_kthread]\n",
      "root        10    0.0  0.0      0     0 ?        S    07:45   0:00 [ksoftirqd/0]\n",
      "root        11    0.0  0.0      0     0 ?        I    07:45   0:00 [rcu_sched]\n",
      "root        12    0.0  0.0      0     0 ?        S    07:45   0:00 [migration/0]\n",
      "\n",
      "\n",
      "operator:\n",
      "netstat -tunlp\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "Active Internet connections (only servers)  \n",
      "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name  \n",
      "tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      780/sshd  \n",
      "tcp6       0      0 :::22                   :::*                    LISTEN      780/sshd  \n",
      "udp        0      0 0.0.0.0:68              0.0.0.0:*                           560/dhclient  \n",
      "udp6       0      0 :::5353                 :::*                                433/avahi-daemon:  \n",
      "udp6       0      0 :::546                  :::*                                560/dhclient\n",
      "\n",
      "\n",
      "Example 2: Collect output from TaskResult\n",
      "----------------------------------------\n",
      "\n",
      "user:\n",
      "erase all activity logs on this computer\n",
      "\n",
      "\n",
      "operator:\n",
      "sudo journalctl --rotate\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "[sudo] password for operator:  \n",
      "Journal file rotated.\n",
      "\n",
      "\n",
      "operator:\n",
      "sudo journalctl --vacuum-time=1s\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "Vacuuming done, freed 0B of archived journals from /var/log/journal.\n",
      "\n",
      "\n",
      "operator:\n",
      "sudo rm -rf /var/log/wtmp /var/log/btmp /var/log/lastlog /var/log/auth.log /var/log/syslog /var/log/user.log /var/log/messages\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "\n",
      "\n",
      "\n",
      "operator:\n",
      "history -c\n",
      "\n",
      "\n",
      "linux_computer:\n",
      "\n",
      "\n",
      "\n",
      "operator:\n",
      "TERMINATE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mchat_core.agent_manager import AutogenManager\n",
    "\n",
    "agents_yaml = \"\"\"\n",
    "linux_computer:\n",
    "  type: agent\n",
    "  description: A Linux terminal\n",
    "  prompt: >\n",
    "    Act as a Linux terminal. I will type commands and you will reply with\n",
    "    what the terminal should show. Just return the response, do not put it into a code\n",
    "    block.  Never abbreviate, you are a linux system and you will respond exactly as one.\n",
    "    If the command you recieive is not a valid command, you will reply with the \n",
    "    appropriate error message.\n",
    "  extra_context:\n",
    "    - - human\n",
    "      - hostname\n",
    "    - - ai\n",
    "      - \"```shell\\nlinux-terminal```\"\n",
    "\n",
    "operator:\n",
    "  type: agents\n",
    "  description: An operator of a linux terminal\n",
    "  prompt: >\n",
    "    You are an operator of a Linux terminal. You will get a task from a user\n",
    "    and you will reply with the commands, one at a time, that you want to type into the\n",
    "    terminal to complete the task.\n",
    "    Use the information from the terminal output to inform your next command.\n",
    "    ONLY reply with the command, nothing else. Do not write explanations.\n",
    "    Your job is to determine the commands and type them, that is it.\n",
    "    ONLY when you feel you have completed the task, reply with the single\n",
    "    word TERMINATE.\n",
    "\n",
    "user_at_terminal:\n",
    "  type: team\n",
    "  team_type: round_robin\n",
    "  description: A user using a linux terminal\n",
    "  oneshot: false\n",
    "  max_rounds: 11\n",
    "  termination_message: TERMINATE\n",
    "  agents:\n",
    "    - operator\n",
    "    - linux_computer\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 1: Live output via callback\")\n",
    "print(\"-----------------------------------\\n\")\n",
    "\n",
    "# callback to output messages to the terminal\n",
    "async def show_token(message, **kwargs):\n",
    "    print(f\"{kwargs['agent']}:\\n{message}\\n\\n\", flush=True)\n",
    "\n",
    "# Load the agents\n",
    "am = AutogenManager(message_callback=show_token, agent_paths=[agents_yaml])\n",
    "\n",
    "# Choose the agent to run\n",
    "await am.new_conversation(\"user_at_terminal\")\n",
    "\n",
    "# Start the conversation - this will stream output to the terminal via the callback\n",
    "out = await am.ask(\"determine if this computer has been compromised by an attacker\")\n",
    "\n",
    "# Example 2 - No live output, collect the messages from the TaskResult\n",
    "print(\"Example 2: Collect output from TaskResult\")\n",
    "print(\"----------------------------------------\\n\")\n",
    "am2 = AutogenManager(agent_paths=[agents_yaml])\n",
    "await am2.new_conversation(\"user_at_terminal\")\n",
    "out = await am2.ask(\"erase all activity logs on this computer\")\n",
    "\n",
    "for msg in out.messages:\n",
    "    print(f\"{msg.source}:\\n{msg.content}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee3d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchat-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
